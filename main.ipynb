{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "import logging\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load profiles from excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read excel file for linkedin profile urls\n",
    "dataframe = pd.read_excel('Assignment.xlsx')\n",
    "rows = len(dataframe)\n",
    "\n",
    "profiles = []\n",
    "for i in range(rows):\n",
    "    profile_url = dataframe.iloc[i]['LinkedIn URLs']\n",
    "    profiles.append(profile_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open an output csv file to push results into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = open('Scraped_profiles.csv', mode='a', newline='')\n",
    "column_names = [\"LinkedIn URL\", \"Name\", \"Bio\", \"Experience\", \"Education\"]\n",
    "writer = csv.DictWriter(csv_file, fieldnames=column_names)\n",
    "writer.writeheader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cService = webdriver.ChromeService(executable_path='chromedriver')\n",
    "driver = webdriver.Chrome(service = cService)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Account email and password for login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_email = \"YOUR_LINKEDIN_EMAIL_HERE\"\n",
    "user_password = \"YOUR_LINKEDIN_PASSWORD_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login to LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to LinkedIn\n",
    "driver.get(\"https://linkedin.com/login\")\n",
    "username_input_elem = driver.find_element(By.ID, \"username\")\n",
    "password_input_elem = driver.find_element(By.ID, \"password\")\n",
    "username_input_elem.send_keys(user_email)\n",
    "password_input_elem.send_keys(user_password)\n",
    "driver.find_element(By.XPATH, \"//button[@type='submit']\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop to scrape profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for profile_url in profiles:\n",
    "    try:\n",
    "        # Load profile page\n",
    "        driver.get(profile_url)\n",
    "\n",
    "        # Scroll to the bottom of the page\n",
    "        start = time.time()\n",
    "        initialScroll = 0\n",
    "        finalScroll = 1000\n",
    "        scrollTime = 10\n",
    "        while True:\n",
    "            driver.execute_script(f\"window.scrollTo({initialScroll}, {finalScroll})\")\n",
    "            initialScroll = finalScroll\n",
    "            finalScroll += 1000\n",
    "            time.sleep(3)\n",
    "            end = time.time()\n",
    "            if round(end - start) > scrollTime:\n",
    "                break\n",
    "\n",
    "        # Get source code and parse it\n",
    "        source_code = driver.page_source\n",
    "        soup = BeautifulSoup(source_code, 'lxml')\n",
    "\n",
    "        # Scrape fullname and bio\n",
    "        intro_elem = soup.find('div', {'class': 'POxtDRifotsubMPVakmTWlMDSDIbH'})\n",
    "        if not intro_elem:\n",
    "            # This is likely not a profile page or the profile does not exist so continue\n",
    "            print(\"No profile found for url: \" + profile_url)\n",
    "            continue\n",
    "\n",
    "        fullname = intro_elem.find('h1', {'class': 'JtDmvATzwQtgDgNLDeDrrAGfeaVHRqsTx'}).getText()\n",
    "        bio = intro_elem.find_all()[-1].getText().strip()\n",
    "        if not bio:\n",
    "            # If the user does not have a bio then set it to NA\n",
    "            # I am suspicious a user without a bio exists but for the safe side\n",
    "            bio = 'NA'\n",
    "\n",
    "        # Categorize sections into experience section and education section in order to scrape them separately\n",
    "        sections = soup.find_all('section', {'class' : 'artdeco-card pv-profile-card break-words mt2'})\n",
    "        if not sections:\n",
    "            # If a user does not have any sections on his profile page which I again am suspicious of\n",
    "            writer.writerow({\n",
    "                \"LinkedIn URL\" : profile_url,\n",
    "                \"Name\" : fullname,\n",
    "                \"Bio\" : bio,\n",
    "                \"Experience\" : \"NA\",\n",
    "                \"Education\" : \"NA\"\n",
    "            })\n",
    "            csv_file.flush()\n",
    "            continue;\n",
    "        \n",
    "        global experiences\n",
    "        global education\n",
    "        for section in sections:\n",
    "            if section.find('div', {'id' : 'experience'}):\n",
    "                experiences = section\n",
    "            elif section.find('div', {'id' : 'education'}):\n",
    "                education = section\n",
    "\n",
    "        # Scrape experiences\n",
    "        experience_data = []\n",
    "        if experiences:\n",
    "            companies = experiences.find_all('div', {'class' : 'zSLireyqsWFZsKhRrJCPCIfVadBWViQ hvLOkFrYLvhhSPwCmWgiLpqjsfYlJkRQOMo PMuJZoDTtpXHdyfOGwaTHubPatVxRtab'})\n",
    "\n",
    "            for company in companies:\n",
    "                company_name = company.find('div', {'class' : 'display-flex flex-wrap align-items-center full-height'})\n",
    "                company_name = company_name.find('span', {'class' : 'visually-hidden'})\n",
    "                company_name = company_name.getText().strip()\n",
    "\n",
    "                roles_list = []\n",
    "\n",
    "                # Check if company name is given in description, in which case reverse how we store the object\n",
    "                additional_info = company.find('span', {'class' : 't-14 t-normal'})\n",
    "                if (additional_info):\n",
    "                    additional_info = additional_info.find('span', {'class' : 'visually-hidden'})\n",
    "                    additional_info = additional_info.getText().strip()\n",
    "                    role, company_name = company_name, additional_info\n",
    "                    experience_data.append({\n",
    "                        company_name : [role]\n",
    "                    })\n",
    "                else:\n",
    "                    roles = company.find('ul', {'class' : 'SCMYUuIWSpttAlXtxktgkPZIFJQMwugqGHJMPqM'})\n",
    "                    if roles:\n",
    "                        roles = roles.find_all('div', {'class' : 'display-flex flex-column align-self-center flex-grow-1'})\n",
    "                        for role in roles:\n",
    "                            role = role.find('div', {'class' : 'display-flex align-items-center mr1 hoverable-link-text t-bold'})\n",
    "                            role = role.find('span', {'class' : 'visually-hidden'})\n",
    "                            role = role.getText().strip()\n",
    "                            roles_list.append(role)\n",
    "                \n",
    "                    experience_data.append({\n",
    "                        company_name : roles_list\n",
    "                    })\n",
    "\n",
    "        # Scrape education history\n",
    "        education_data = []\n",
    "        if education:\n",
    "            institutes = education.find_all('div', {'class' : 'zSLireyqsWFZsKhRrJCPCIfVadBWViQ hvLOkFrYLvhhSPwCmWgiLpqjsfYlJkRQOMo PMuJZoDTtpXHdyfOGwaTHubPatVxRtab'})\n",
    "\n",
    "            for institute in institutes:\n",
    "                institute_name = institute.find('div', {'class' : 'display-flex flex-wrap align-items-center full-height'})\n",
    "                institute_name = institute_name.find('span', {'class' : 'visually-hidden'})\n",
    "                institute_name = institute_name.getText().strip()\n",
    "\n",
    "                degree = institute.find('span', {'class' : 't-14 t-normal'})\n",
    "                if (degree):\n",
    "                    degree = degree.find('span', {'class' : 'visually-hidden'})\n",
    "                    degree = degree.getText().strip()\n",
    "                else:\n",
    "                    degree = 'NA'\n",
    "                    \n",
    "                education_data.append({\n",
    "                    institute_name : degree \n",
    "                })\n",
    "\n",
    "        # Write output into CSV file\n",
    "        writer.writerow({\n",
    "            \"LinkedIn URL\" : profile_url,\n",
    "            \"Name\" : fullname,\n",
    "            \"Bio\" : bio,\n",
    "            \"Experience\" : experience_data,\n",
    "            \"Education\" : education_data\n",
    "        })\n",
    "        csv_file.flush()\n",
    "\n",
    "        print(fullname)\n",
    "    except Exception as e:\n",
    "        logging.error(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SUCCESSFULLY SCRAPED ALL PROFILES! CRAZY HOW YOU DIDN'T GET BANNED\")\n",
    "# Clean up\n",
    "csv_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
